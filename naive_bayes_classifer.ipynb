{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statistics\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_car(filename):\n",
    "    \n",
    "    # read in the data\n",
    "    data = pd.read_csv('car.data',header=None, encoding = 'ISO-8859-1')\n",
    "    # create a Dataframe \n",
    "    car_data = pd.DataFrame(data)\n",
    "    # X_car is a dataframe containing features \n",
    "    X_car = car_data.loc[:, 0:car_data.shape[1]-2]\n",
    "    # y_car is a series containing class labels\n",
    "    y_car = car_data.loc[:, car_data.shape[1] - 1]\n",
    "    # returns a data frame of the feature values and a series of the class labels\n",
    "    return X_car, y_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is to change the ordinal car data to numeric \n",
    "\n",
    "def car_numeric_data(filename):\n",
    "    \n",
    "    # this block of code is modified from Practical week 4 Machine Learning, University of Melbourne\n",
    "    X = []\n",
    "    y = []\n",
    "    with open('car.data', mode='r') as fin:\n",
    "        for line in fin:\n",
    "            atts = line.strip().split(\",\")\n",
    "            # all features, excluding the class\n",
    "            X.append(atts[:-1]) \n",
    "            # class labels \n",
    "            y.append(atts[-1])\n",
    "            \n",
    "    # need to hard code the possible feature values as there is no way to sort them into their orders\n",
    "    feature_lst = [['low', 'med', 'high','vhigh'], ['low', 'med', 'high','vhigh'], ['2','3','4','5more'],\\\n",
    "                   ['2','4', 'more'], ['small', 'med', 'big'], ['low', 'med', 'high']]\n",
    "    \n",
    "\n",
    "    X_ordinal = []\n",
    "    # go though each row in the data \n",
    "    for row in X:\n",
    "        # stores the numeric values for each value in the row\n",
    "        numericisedValues = []\n",
    "        # for each value, add the index of it from feature_lst to the numericisedValues\n",
    "        for i in range(len(row)):\n",
    "            numericisedValues.append(feature_lst[i].index(row[i]))\n",
    "        # add this list to the X_ordinal list (this will end up as a row in a data frame)\n",
    "        X_ordinal.append(numericisedValues)\n",
    "\n",
    "    #convert to dataframe \n",
    "    X_car_ordinal = pd.DataFrame(data=X_ordinal) \n",
    "    # convert to a series \n",
    "    y_car = pd.Series(data=y)\n",
    "\n",
    "    # returns a data frame of the feature values and a series of the class labels                    \n",
    "    return X_car_ordinal, y_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_wdbc(filename):\n",
    "    \n",
    "    # read in the data\n",
    "    data = pd.read_csv('wdbc.data',header=None,encoding = 'ISO-8859-1')\n",
    "    # create a Dataframe \n",
    "    wdbc_data = pd.DataFrame(data)\n",
    "    #X_wdbc is a dataframe containing features \n",
    "    X_wdbc = wdbc_data.loc[:, 2:]\n",
    "    # y_wdbc is a dataframe containing class labels\n",
    "    y_wdbc = wdbc_data.loc[:, 1]\n",
    "    \n",
    "    # reset the indicies of the columns\n",
    "    X_wdbc.columns = range(X_wdbc.shape[1])\n",
    "    \n",
    "    # change data to numeric \n",
    "    for col in range(len(X_wdbc.columns)):\n",
    "        X_wdbc[col] = pd.to_numeric(X_wdbc[col])\n",
    "        \n",
    "    # returns a data frame of the feature values and a series of the class labels      \n",
    "    return X_wdbc, y_wdbc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_wine(filename):\n",
    "    \n",
    "    # read in the data\n",
    "    data = pd.read_csv('wine.data',header=None,encoding = 'ISO-8859-1')\n",
    "    # create a Dataframe \n",
    "    wine_data = pd.DataFrame(data)\n",
    "    # X_wine is a dataframe containing features \n",
    "    X_wine = wine_data.loc[:, 1:]\n",
    "    # y_wine is a dataframe containing class labels\n",
    "    y_wine = wine_data.loc[:, 0]\n",
    "    \n",
    "    # reset the indicies of the columns\n",
    "    X_wine.columns = range(X_wine.shape[1])\n",
    "    \n",
    "    # change data to numeric \n",
    "    for col in range(len(X_wine.columns)):\n",
    "        X_wine[col] = pd.to_numeric(X_wine[col])\n",
    "    \n",
    "    # returns a data frame of the feature values and a series of the class labels        \n",
    "    return X_wine, y_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mushroom(filename):\n",
    "    \n",
    "    # read in the data\n",
    "    data = pd.read_csv('mushroom.data',header=None,encoding = 'ISO-8859-1')\n",
    "    # create a Dataframe \n",
    "    mush_data = pd.DataFrame(data)\n",
    "    \n",
    "    # remove the instances which have a '?' as a value for the attribute at index 11\n",
    "    mush_data_clean = mush_data[mush_data[11] != '?'].reset_index(drop = True) \n",
    "    \n",
    "    # X_mush is a dataframe containing features \n",
    "    X_mush = mush_data_clean.loc[:, 1:mush_data.shape[1]-1]\n",
    "    # y_mush is a series containing class labels\n",
    "    y_mush = mush_data_clean.loc[:,0]\n",
    "    # reset the indicies of the columns\n",
    "    X_mush.columns = range(X_mush.shape[1])\n",
    "    \n",
    "    # returns a data frame of the feature values and a series of the class labels  \n",
    "    return X_mush, y_mush, mush_data_clean, mush_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_bank(filename):\n",
    "    \n",
    "    # read in the data\n",
    "    data = pd.read_csv('bank.data',header=None,encoding = 'ISO-8859-1')\n",
    "    # create a Dataframe \n",
    "    bank_data = pd.DataFrame(data) \n",
    "    # X_bank is a dataframe containing features \n",
    "    X_bank = bank_data.loc[:, 0:bank_data.shape[1]-2]\n",
    "    # y_bank is a series containing class labels\n",
    "    y_bank = bank_data.loc[:,bank_data.shape[1]-1]\n",
    "    # returns a data frame of the feature values and a series of the class labels  \n",
    "    \n",
    "    return X_bank, y_bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesses selected data\n",
    "def preprocess(name):\n",
    "    \n",
    "    if name == 'bank':\n",
    "        X, y = preprocess_bank('bank.data')\n",
    "        \n",
    "    elif name == \"car\":\n",
    "        X, y = preprocess_car('car.data')\n",
    "        \n",
    "    elif name == \"carNumeric\":\n",
    "        X, y = car_numeric_data('car.data')\n",
    "        \n",
    "    elif name == \"nursery\":\n",
    "        X, y = preprocess_nursery('nursery.data')\n",
    "        \n",
    "    elif name == \"nurseryNumeric\":\n",
    "        X, y = nursery_numeric_data('nursery.data')\n",
    "        \n",
    "    elif name == \"somervilleNumeric\":\n",
    "        X, y = somerville_numeric_data('somerville.data')\n",
    "        \n",
    "    elif name == \"somerville\":\n",
    "        X, y = preprocess_somerville('somerville.data')\n",
    "        \n",
    "    elif name == \"wdbc\":\n",
    "        X, y = preprocess_wdbc('wdbc.data')\n",
    "        \n",
    "    elif name == \"wine\":\n",
    "        X, y = preprocess_wine('wine.data')\n",
    "        \n",
    "    elif name == \"mushroom\":\n",
    "        X, y  = preprocess_mushroom('mushroom.data')\n",
    "        \n",
    "    else: \n",
    "        print(\"Invalid argument.\")\n",
    "        X, y = None, None\n",
    "    \n",
    "    # returns a preprocessed datafame X of the features and series y, the classes. \n",
    "    return X, y\n",
    "\n",
    "\n",
    "# split the data into test and train datasets \n",
    "def test_train(X,y,rand_state):\n",
    "    \n",
    "    # initalie a list to save which features are numeric and if they are categorical \n",
    "    # save the possible values that each feature can take in a further nested list \n",
    "    unique_vals = []\n",
    "    \n",
    "    for index, col in X.iteritems():\n",
    "        # if the first value of the column is either type float or int \n",
    "        if isinstance(col[0], float) or isinstance(col[0], (int, np.integer)):\n",
    "            # add a 0 to the current index of the unique_vals list\n",
    "            unique_vals.append(0)\n",
    "        # if the first value of the column is type string \n",
    "        elif isinstance(col[0], str):\n",
    "            # add a list of the unique values to the current index of the unique_vals list\n",
    "            unique_vals.append(list(col.unique()))\n",
    "    \n",
    "    # returns X_train, X_test, y_train, y_test data frames and the list unique_vals\n",
    "    return train_test_split(X, y, test_size=0.3333, random_state=rand_state), unique_vals\n",
    "\n",
    "# trains the data \n",
    "def train(X, y, unique_vals):\n",
    "    \n",
    "    # find the unique classes and how many of each class \n",
    "    \n",
    "    class_values = y.value_counts()\n",
    "    \n",
    "    priors = {}\n",
    "    \n",
    "    # make a dictionary to hold the prior associated with each class\n",
    "    for index, class_count in class_values.iteritems():\n",
    "        # take the log of the priors to prevent underflow error\n",
    "        priors[index] = math.log(class_count/len(y)) \n",
    "        \n",
    "    # initalise a dataframe to hold the parameters we will need for the testing phase \n",
    "    conditional_probs = pd.DataFrame(columns=class_values.index)\n",
    "\n",
    "    \n",
    "    # loop over every column in the training set\n",
    "    for index, col in X.iteritems():\n",
    "    \n",
    "        # first is to check whether the column is numeric or nominal to can handle mixed dataframes \n",
    "        \n",
    "        # This 'if' statement selects for numeric data that matches the int or float types.\n",
    "        if isinstance(col.iloc[0], float) or isinstance(col.iloc[0], (int, np.integer)):\n",
    "            \n",
    "            # create a dictionary to store the values in a list assoicated with each class\n",
    "            \n",
    "            values_per_class = {}\n",
    "            \n",
    "            # inialise each key value (which are the possible classes) as an empty list\n",
    "            for cls in class_values.index:\n",
    "                values_per_class[cls] = []\n",
    "                \n",
    "            \n",
    "            # Iterate through the rows of the currently examined column and split them into class lists.\n",
    "            for row_index, row_value in col.iteritems():\n",
    "                # itterate for how many classes the data set has\n",
    "                for i in range(len(class_values.index)):\n",
    "                    # add the value to the list for the correct class \n",
    "                    values_per_class[y[row_index]].append(row_value)\n",
    "                    \n",
    "            # create a dict to store mean and standard deviation of each class list \n",
    "            mu_sigma = {}\n",
    "            \n",
    "            # itterate for how many classes the data set has\n",
    "            for cls in class_values.index:\n",
    "                \n",
    "                # add the mean as the first index and the standard deviation as the 2nd index for each mu_sigma value\n",
    "                mu_sigma[cls] = [statistics.mean(values_per_class[cls]), statistics.stdev(values_per_class[cls])]\n",
    "                \n",
    "            # add the dict as a row in the conditional_probs dataframe\n",
    "            conditional_probs = conditional_probs.append(mu_sigma, ignore_index=True)\n",
    "        \n",
    "        # This 'if' statement selects for nominal data that matches the str types.\n",
    "        elif isinstance(col.iloc[0], str):\n",
    "\n",
    "            # find all the possible values that the feature can take\n",
    "            feature_vals = unique_vals[index]\n",
    "\n",
    "            # create dictionaries, one for each class to hold the counts\n",
    "            \n",
    "            probs_per_class = {}\n",
    "            \n",
    "            for cls in class_values.index:\n",
    "                # inialise each key value (which are the classes) as an empty list\n",
    "                probs_per_class[cls] = {}\n",
    "                 # Initialise values in dictionary. Begin at 1 for smoothing.\n",
    "                for value in feature_vals:\n",
    "                    probs_per_class[cls][value] = 1\n",
    "\n",
    "\n",
    "            # Calculate counts for each unique value.\n",
    "            for row_index, row_value in col.iteritems():\n",
    "                # for each observed value, add one to the count value\n",
    "                for i in range(len(class_values.index)):\n",
    "                    probs_per_class[y[row_index]][row_value] += 1\n",
    "                    \n",
    "            # find the conditional probability of each value given its class and store in dictonary \n",
    "            for value in feature_vals:\n",
    "                for cls in class_values.index:\n",
    "                    # conditional probability equals the amount of times this value appears for each class (plus one for smoothing)\n",
    "                    # divided by the sum of the amount of data points corresponding to this \n",
    "                    # class and how many possible unique values there are for this feature \n",
    "                    probs_per_class[cls][value] = probs_per_class[cls][value] / (class_values[cls] + len(feature_vals))\n",
    "           \n",
    "            # add the dictionary as a row in the dataframe   \n",
    "            conditional_probs = conditional_probs.append(probs_per_class, ignore_index=True)\n",
    "            \n",
    "    # return a dataframe holding the mean and standard deviation values for numeric features \n",
    "    # or the conditional probabilities for nominal features, a dictionary of the prior values for each class\n",
    "    # and a series, class_values of the unique classes and counts for each class\n",
    "    return conditional_probs, priors, class_values\n",
    "\n",
    "\n",
    "# This function should predict classes for new items in a test dataset\n",
    "\n",
    "def predict(conditional_probs, priors, class_values, X_test, unique_vals):\n",
    "    \n",
    "    # initalise a list to hold the predicted class for each instance \n",
    "    predicted_class = []\n",
    "    # for each instance (row in the test set)\n",
    "    for index, row in X_test.iterrows():  \n",
    "        \n",
    "        # initalsie a dictonary to hold the probabilities for each class \n",
    "        probs = {}\n",
    "        for cls in class_values.index:\n",
    "            # initalise each key in the dictonary as one of the unique classes and make the corresponding\n",
    "            # value the prior for that class \n",
    "            probs[cls] = priors[cls]\n",
    "                \n",
    "        # this will be the same number of times as looping through the row \n",
    "        for i in X_test.columns:\n",
    "            \n",
    "            # if numeric: as all nominal data is stored in a list \n",
    "            if unique_vals[i] == 0:\n",
    "                \n",
    "                # conditional_probs[col][i][0] is the value of mu for each class\n",
    "                # conditional_probs[col][i][1] is the value of sigma for each class \n",
    "                \n",
    "                for cls in class_values.index:\n",
    "                    # have this if statment for when treating ordinal data as numeric, as the data is still discrete\n",
    "                    # there were a couple of 0 standard deviations, where as this is impossible for \n",
    "                    # continuous data\n",
    "                    if conditional_probs[cls][i][1] == 0:\n",
    "                        # instead make the standard deviation very small to aviod math error \n",
    "                        conditional_probs[cls][i][1] = 1.0e-100\n",
    "                        \n",
    "                    # add the conditional probability to the total proabaility for each class \n",
    "                    probs[cls] += conditional_probability(conditional_probs[cls][i][0], conditional_probs[cls][i][1], row.iloc[i])\n",
    "            # all nominal data is stored in a dictonary \n",
    "                       \n",
    "            elif type(unique_vals[i]) == list:\n",
    "                for cls in class_values.index:\n",
    "                    probs[cls] += math.log(conditional_probs[cls][i][row.iloc[i]])\n",
    "                    \n",
    "        #Predict the outcome\n",
    "                                           \n",
    "        sorted_probs = sorted(probs.items(), key=lambda x: x[1])\n",
    "        predicted_class.append(sorted_probs[-1][0])\n",
    "        \n",
    "    return predicted_class \n",
    "\n",
    "# this function is for implementing the conditional probailty formula for numeric attributes \n",
    "# it takes the mean, standard deviation for each feature and the observed value from the test set.\n",
    "def conditional_probability(mu, sigma, obs):\n",
    "    \n",
    "    # log likelihood was taken \n",
    "    # simplified from: log(1/denominator) + log(exp(exponent))\n",
    "    # to become:  exponent - log(denominator) using the properties of exponents and logarithims \n",
    "    # this was to handle the math error as log(0) is undefined \n",
    "    denominator = sigma*(math.sqrt(2*math.pi))\n",
    "    exponent = -0.5*(((obs-mu)/sigma)**2)\n",
    "    \n",
    "    likelihood = exponent - math.log(denominator)\n",
    "    # returns the likelihood (condtional probability)\n",
    "    return likelihood\n",
    "\n",
    "\n",
    "# This function should evaluate the prediction performance by comparing your model’s class outputs to ground\n",
    "# truth labels\n",
    "def evaluate(predicted_class, y_test):\n",
    "    \n",
    "    \n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_test, predicted_class)\n",
    "    \n",
    "    # the proportion of the correctly labeled instances \n",
    "    accuracy = accuracy_score(y_test, predicted_class)\n",
    "  \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run on any data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8824739531488486"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_model(data):\n",
    "    \n",
    "    X, y = preprocess(data)\n",
    "\n",
    "    # split data into train and test datasets\n",
    "    (X_train, X_test, y_train, y_test), unique_vals =  test_train(X, y, rand_state = 20) \n",
    "\n",
    "    # train data \n",
    "    conditional_probs, priors, class_values = train(X_train, y_train, unique_vals)\n",
    "\n",
    "    # predict on unseen data\n",
    "    predicted_class = predict(conditional_probs, priors, class_values, X_test, unique_vals)\n",
    "\n",
    "    # evaluate prediction and return accuracy\n",
    "    return evaluate(predicted_class, y_test)\n",
    "\n",
    "\n",
    "run_model('bank')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
